
@misc{aisharenet-kitools,
	title = {Die 5 besten {KI}-{Agenten}-{Frameworks}, die sich im {Jahr} 2025 lohnen},
	url = {https://www.aisharenet.com/de/2025nianzhiderukengai/},
	abstract = {Agent Die häufigste Übersetzung, die ich bisher gesehen habe, ist "intelligenter Körper", aber die direkte Übersetzung ist "Agent". Was sollte mit Agentic übersetzt werden? Meiner Meinung nach ist der Begriff "agentic" besser geeignet. Um also die Leser nicht zu verwirren, verwende ich in diesem Artikel direkt das Englische.   Mit der Entwicklung von LLM, der Fähigkeit der KI...},
	language = {zh-CN},
	urldate = {2025-02-03},
	journal = {Chef-KI-Austauschkreis},
}


@misc{phidata, 
    author = {Phidata}, 
    title = {Phidata - How engineers build AI agents}, 
    year = {2024}, 
    url = {https://www.phidata.com/} ,
    urldate = {2025-02-03},
}

@misc{microsoft_semantic_kernel_agent_framework, 
    author = {Microsoft}, 
    title = {Semantic Kernel Agent Framework (Experimental)}, 
    year = {2024}, 
    url = {https://learn.microsoft.com/de-de/semantic-kernel/frameworks/agent/},
    urldate = {2025-02-03},
}

@misc{phidata_introduction, 
    author = {Phidata}, 
    title = {Phidata: Introduction}, 
    year = {2024}, 
    url = {https://docs.phidata.com/introduction} ,
    urldate = {2025-02-03},
}

@misc{phidata_vs_langchain_comparison, 
    author = {Restackio}, 
    title = {Phidata Vs Langchain Comparison}, 
    year = {2024}, 
    url = {https://www.restack.io/p/phidata-answer-vs-langchain-cat-ai?utm_source=chatgpt.com},
    urldate = {2025-02-03},
}

@misc{microsoft-autogen,
    title = {Microsoft Autogen: The AI Agent Framework}, 
    author = {Microsoft}, 
    year = {2024}, 
    url = {https://microsoft.github.io/autogen/0.2/docs/Getting-Started},
    urldate = {2025-02-03},
}

@misc{crewai,
    title = {Crew AI: The AI Agent Framework}, 
    author = {Crew AI}, 
    year = {2024}, 
    url = {https://www.crewai.com/enterprise},
    urldate = {2025-02-03},
}


@misc{phidata_sqliteagent,
	title = {Sqlite {Agent} {Storage}},
	url = {https://docs.phidata.com/storage/sqlite},
	language = {en},
	urldate = {2025-02-04},
	journal = {Phidata},
}


@misc{ibm_instruction_tuning,
	title = {What {Is} {Instruction} {Tuning}? {\textbar} {IBM}},
	shorttitle = {What {Is} {Instruction} {Tuning}?},
	url = {https://www.ibm.com/think/topics/instruction-tuning},
	abstract = {Instruction tuning is a technique for fine-tuning large language models (LLMs) to improve model performance on natural language instruction following.},
	language = {en},
	urldate = {2025-02-07},
	month = apr,
	year = {2024},
}

@misc{xarchives_instruction_tuning, 
	title = {Instruction {Tuning} for {Large} {Language} {Models}: {A} {Survey}},
    author = {Shengyu Zhang and Linfeng Dong and Xiaoya Li and Sen Zhang},
    year = {2024},
    month = mar,
    day = {14},
	url = {https://arxiv.org/html/2308.10792v5},
	urldate = {2025-02-07},
}


@misc{roth_researchers_2025,
	title = {Researchers trained an {OpenAI} rival in half an hour for less than \$50},
	url = {https://www.theverge.com/news/607341/researchers-cheaper-openai-rival-training},
	abstract = {Doing a DeepSeek.},
	language = {en-US},
	urldate = {2025-02-07},
	journal = {The Verge},
	author = {Roth, Emma},
	month = feb,
	year = {2025},
}
